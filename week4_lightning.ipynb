{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WAywfKXReZha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB3b90XvF-uD"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import MNIST\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "mnist_train = MNIST('./mnist', download=True)\n",
        "mnist_text = MNIST('./mnist', download=True, train=False)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.Lambda(lambda x: torch.flatten(x))\n",
        "    ])\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = MNIST('./mnist', train=True, transform=transform, download=True)\n",
        "validation_set = MNIST('./mnist', train=False, transform=transform, download=True)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=8, shuffle=True,\n",
        "                                              num_workers=4, pin_memory=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
        "\n",
        "# PyTorch models inherit from torch.nn.Module\n",
        "class MNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(784, 128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.layers(x) # [batch_size, 784] --> [batch_size, 10]\n",
        "        return x\n",
        "\n",
        "model = MNISTClassifier()\n",
        "model = model.cuda()\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss() # sum_i p_i logp_i\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(training_loader):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            avg_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, avg_loss))\n",
        "            tb_x = epoch * len(training_loader) + i + 1\n",
        "            writer.add_scalar('Loss/train', avg_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(validation_loader):\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            outputs = model(x)\n",
        "            loss = loss_fn(outputs, y)\n",
        "            running_vloss += loss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "JyNNxC-iI6wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import lightning as pl\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "# Define the LightningModule\n",
        "class MNISTClassifier(pl.LightningModule):\n",
        "    def __init__(self, learning_rate=0.001):\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(784, 128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.val_logits = []\n",
        "        self.val_labels = []\n",
        "        self.val_accuracy = Accuracy('multiclass', num_classes=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "\n",
        "        # Store logits and labels for later calculation\n",
        "        self.val_logits.append(logits)\n",
        "        self.val_labels.append(y)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        # Concatenate all stored logits and labels\n",
        "        val_logits = torch.cat(self.val_logits, dim=0)\n",
        "        val_labels = torch.cat(self.val_labels, dim=0)\n",
        "\n",
        "        # Calculate the average loss over the entire validation set\n",
        "        avg_val_loss = self.loss_fn(val_logits, val_labels)\n",
        "\n",
        "        # Calculate accuracy using torchmetrics\n",
        "        avg_val_acc = self.val_accuracy(val_logits, val_labels)\n",
        "\n",
        "        # Log the average validation loss and accuracy\n",
        "        self.log('val_loss', avg_val_loss, prog_bar=True)\n",
        "        self.log('val_acc', avg_val_acc, prog_bar=True)\n",
        "\n",
        "        # Clear the lists for the next epoch\n",
        "        self.val_logits = []\n",
        "        self.val_labels = []\n",
        "        self.val_accuracy.reset()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.parameters(), lr=self.learning_rate, momentum=0.9)"
      ],
      "metadata": {
        "id": "SUGVzma9RLRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "# Data preparation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.Lambda(lambda x: torch.flatten(x))\n",
        "])\n",
        "\n",
        "train_dataset = MNIST('./mnist', train=True, transform=transform, download=True)\n",
        "val_dataset = MNIST('./mnist', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Instantiate the model\n",
        "model = MNISTClassifier()\n",
        "\n",
        "# Instantiate the Trainer\n",
        "tb_logger = TensorBoardLogger(save_dir=\"logs/\", name=\"cnn\")\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=5,\n",
        "                     accelerator=\"gpu\",\n",
        "                     devices=1,\n",
        "                     log_every_n_steps=1000,\n",
        "                     logger=tb_logger)\n",
        "\n",
        "# Train the model\n",
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "zODI_be2M_8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "class MNISTCNN(MNISTClassifier):\n",
        "    def __init__(self, learning_rate=0.001):\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Sigmoid(), ## nn.ReLu\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Sigmoid(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Sigmoid(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 10, kernel_size=1, stride=1, padding=0),\n",
        "        )\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.val_logits = []\n",
        "        self.val_labels = []\n",
        "        self.val_accuracy = Accuracy('multiclass', num_classes=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = x.mean([2, 3])\n",
        "        return x\n",
        "\n",
        "# Data preparation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "#    transforms.Lambda(lambda x: torch.flatten(x))\n",
        "])\n",
        "\n",
        "train_dataset = MNIST('./mnist', train=True, transform=transform, download=True)\n",
        "val_dataset = MNIST('./mnist', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Instantiate the model\n",
        "model = MNISTCNN(0.0001)\n",
        "\n",
        "# Instantiate the Trainer\n",
        "tb_logger = TensorBoardLogger(save_dir=\"logs/\", name=\"cnn\")\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=5,\n",
        "                     accelerator=\"gpu\",\n",
        "                     devices=1,\n",
        "                     log_every_n_steps=1000,\n",
        "                     logger=tb_logger)\n",
        "\n",
        "# Train the model\n",
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "sC7HhBukdYJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorboard\n",
        "%load_ext tensorboard\n",
        "\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "%tensorboard --logdir logs/"
      ],
      "metadata": {
        "id": "S78TmhXgTsOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vht6xeNH1d-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm logs -rf"
      ],
      "metadata": {
        "id": "mpyDY2w6Uig7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5E8gRiVBUj4R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}